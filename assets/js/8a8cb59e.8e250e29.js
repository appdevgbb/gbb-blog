"use strict";(globalThis.webpackChunkdocusaurus=globalThis.webpackChunkdocusaurus||[]).push([[496],{92:(e,t,n)=>{n.r(t),n.d(t,{assets:()=>c,contentTitle:()=>o,default:()=>u,frontMatter:()=>i,metadata:()=>s,toc:()=>l});var s=n(3076),a=n(4848),r=n(8453);const i={authors:["steve_griffith"],date:"2024-08-15",description:"Using Azure Stream Analytics to filter Kubernetes control plane log data from AKS diagnostics in order to isolate critical data and reduce log retention cost.",tags:[],title:"Using Stream Analytics to Filter AKS Control Plane Logs"},o="Filtering AKS Control Plane Logs with Azure Stream Analytics",c={authorsImageUrls:[void 0]},l=[{value:"Introduction",id:"introduction",level:2},{value:"Cluster &amp; Stream Analytics Setup",id:"cluster--stream-analytics-setup",level:2},{value:"Stream Analytics",id:"stream-analytics",level:2},{value:"Create the Service Bus Queue",id:"create-the-service-bus-queue",level:3},{value:"Stream Analytics Job",id:"stream-analytics-job",level:3},{value:"Setup a test workload to trigger audit log entries",id:"setup-a-test-workload-to-trigger-audit-log-entries",level:2},{value:"Update Stream Analytics to Look for Forbidden Requests",id:"update-stream-analytics-to-look-for-forbidden-requests",level:2},{value:"Conclusion",id:"conclusion",level:2}];function d(e){const t={a:"a",blockquote:"blockquote",code:"code",h2:"h2",h3:"h3",img:"img",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",...(0,r.R)(),...e.components};return(0,a.jsxs)(a.Fragment,{children:[(0,a.jsx)(t.h2,{id:"introduction",children:"Introduction"}),"\n",(0,a.jsxs)(t.p,{children:["While AKS does NOT provide access to the cluster's managed control plane, it does provide access to the control plane component logs via ",(0,a.jsx)(t.a,{href:"https://learn.microsoft.com/en-us/azure/aks/monitor-aks#aks-control-planeresource-logs",children:"diagnostic settings"}),". The easiest option to persist and search this data is to send it directly to Azure Log Analytics, however there is a LOT of data in those logs, which makes it cost prohibitive in Log Analytics. Alternatively, you can send all the data to an Azure Storage Account, but then searching and alerting can be challenging."]}),"\n",(0,a.jsx)(t.p,{children:"To address the above challenge, one option is to stream the data to Azure Event Hub, which then gives you the option to use Azure Stream Analytics to filter out events that you deem important and then just store the rest in cheaper storage (ex. Azure Storage) for potential future diagnostic needs."}),"\n",(0,a.jsx)(t.p,{children:"In this walkthrough we'll create an AKS cluster, enable diagnostic logging to Azure Stream Analytics and then demonstrate how to filter out some key records."}),"\n",(0,a.jsx)(t.h2,{id:"cluster--stream-analytics-setup",children:"Cluster & Stream Analytics Setup"}),"\n",(0,a.jsx)(t.p,{children:"In this setup, the cluster will be a very basic single node AKS cluster that will simply have diagnostic settings enabled. We'll also create the Event Hub instance that will be used in the diagnostic settings."}),"\n",(0,a.jsx)(t.pre,{children:(0,a.jsx)(t.code,{className:"language-bash",children:'# Set some environment variables\nRG=LogFilteringLab\nLOC=eastus2\nCLUSTER_NAME=logfilterlab\nNAMESPACE_NAME="akscontrolplane$RANDOM"\nEVENT_HUB_NAME="logfilterhub$RANDOM"\nDIAGNOSTIC_SETTINGS_NAME="demologfilter"\n\n# Create a resource group\naz group create -n $RG -l $LOC\n\n# Create the AKS Cluster\naz aks create \\\n-g $RG \\\n-n $CLUSTER_NAME \\\n-c 1\n\n# Get the cluster credentials\naz aks get-credentials -g $RG -n $CLUSTER_NAME\n\n# Create an Event Hub Namespace\naz eventhubs namespace create --name $NAMESPACE_NAME --resource-group $RG -l $LOC\n\n# Create an event hub\naz eventhubs eventhub create --name $EVENT_HUB_NAME --resource-group $RG --namespace-name $NAMESPACE_NAME\n\nAKS_CLUSTER_ID=$(az aks show -g $RG -n $CLUSTER_NAME -o tsv --query id)\nEVENT_HUB_NAMESPACE_ID=$(az eventhubs namespace show -g $RG -n $NAMESPACE_NAME -o tsv --query id)\n\n# Apply the diagnostic settings to the AKS cluster to enable Kubernetes audit log shipping\n# to our Event Hub\naz monitor diagnostic-settings create \\\n--resource $AKS_CLUSTER_ID \\\n-n $DIAGNOSTIC_SETTINGS_NAME \\\n--event-hub $EVENT_HUB_NAME \\\n--event-hub-rule "${EVENT_HUB_NAMESPACE_ID}/authorizationrules/RootManageSharedAccessKey" \\\n--logs \'[ { "category": "kube-audit", "enabled": true, "retentionPolicy": { "enabled": false, "days": 0 } } ]\' \n'})}),"\n",(0,a.jsx)(t.h2,{id:"stream-analytics",children:"Stream Analytics"}),"\n",(0,a.jsx)(t.p,{children:"As we'll use Stream Analytics to filter through the log messages for what we want to capture, we'll need to create a Stream Analytics Job. This job will take the Event Hub as it's input source, will run a query and will send the query results to an output target. This output target can be a number of options, but for the purposes of our test we'll write the filtered records out to a Service Bus Queue, which we can watch in real time."}),"\n",(0,a.jsx)(t.p,{children:"We have the Event Hub already, now lets create the Azure Service Bus Queue and then the Stream Analytics Job to tie it all together."}),"\n",(0,a.jsx)(t.h3,{id:"create-the-service-bus-queue",children:"Create the Service Bus Queue"}),"\n",(0,a.jsx)(t.pre,{children:(0,a.jsx)(t.code,{className:"language-bash",children:"SERVICE_BUS_NAMESPACE_NAME=kubecontrolplanelogs\nSERVICE_BUS_QUEUE_NAME=kubeaudit\n\n# Create the service bus namespace\naz servicebus namespace create --resource-group $RG --name $SERVICE_BUS_NAMESPACE_NAME --location $LOC\n\n# Create the service bus queue\naz servicebus queue create --resource-group $RG --namespace-name $SERVICE_BUS_NAMESPACE_NAME --name $SERVICE_BUS_QUEUE_NAME\n\n"})}),"\n",(0,a.jsx)(t.h3,{id:"stream-analytics-job",children:"Stream Analytics Job"}),"\n",(0,a.jsxs)(t.p,{children:["For the Stream Analytics Job we'll switch over to the portal, so go ahead and open ",(0,a.jsx)(t.a,{href:"https://portal.azure.com",children:"https://portal.azure.com"})," and navigate to your resource group."]}),"\n",(0,a.jsxs)(t.ol,{children:["\n",(0,a.jsxs)(t.li,{children:["\n",(0,a.jsx)(t.p,{children:"Click on the 'Create' button at the top of your resource group:"}),"\n",(0,a.jsx)(t.p,{children:(0,a.jsx)(t.img,{alt:"Create",src:n(3178).A+"",width:"782",height:"336"})}),"\n"]}),"\n",(0,a.jsxs)(t.li,{children:["\n",(0,a.jsx)(t.p,{children:"Search for 'Stream Analytics Job'"}),"\n",(0,a.jsx)(t.p,{children:(0,a.jsx)(t.img,{alt:"Search",src:n(7883).A+"",width:"815",height:"287"})}),"\n"]}),"\n",(0,a.jsxs)(t.li,{children:["\n",(0,a.jsx)(t.p,{children:"Click 'Create' on the Stream Analytics Job search result"}),"\n",(0,a.jsx)(t.p,{children:(0,a.jsx)(t.img,{alt:"Search Result",src:n(8257).A+"",width:"556",height:"732"})}),"\n"]}),"\n",(0,a.jsxs)(t.li,{children:["\n",(0,a.jsx)(t.p,{children:"Leave all defaults, but provide a name under the 'Instance Details' section and then click 'Review + Create'"}),"\n",(0,a.jsx)(t.p,{children:(0,a.jsx)(t.img,{alt:"Create Instance",src:n(735).A+"",width:"769",height:"968"})}),"\n"]}),"\n",(0,a.jsxs)(t.li,{children:["\n",(0,a.jsx)(t.p,{children:"After the validation is complete, just click 'Create'. This typically completes very quickly."}),"\n"]}),"\n",(0,a.jsxs)(t.li,{children:["\n",(0,a.jsx)(t.p,{children:"Click on 'Go to Resource' or navigate back to your resource group and click on the Stream Analytics Job you just created."}),"\n"]}),"\n",(0,a.jsxs)(t.li,{children:["\n",(0,a.jsx)(t.p,{children:"In the stream analytics job, expand 'Job topology' and then click on 'Inputs' so we can add our Event Hub input"}),"\n",(0,a.jsx)(t.p,{children:(0,a.jsx)(t.img,{alt:"Stream Analytics Job - Add Input",src:n(2428).A+"",width:"733",height:"494"})}),"\n"]}),"\n",(0,a.jsxs)(t.li,{children:["\n",(0,a.jsx)(t.p,{children:"Click on 'Add Input' and select 'Event Hub'"}),"\n",(0,a.jsx)(t.p,{children:(0,a.jsx)(t.img,{alt:"Create Input",src:n(7816).A+"",width:"614",height:"315"})}),"\n"]}),"\n",(0,a.jsxs)(t.li,{children:["\n",(0,a.jsx)(t.p,{children:"The Event Hub's new input creation pane should auto-populate with your Event Hub details as well as default to creation of a new access policy, but verify that all of the details are correct and then click 'Save'."}),"\n",(0,a.jsx)(t.p,{children:(0,a.jsx)(t.img,{alt:"Event Hub Config Details",src:n(3908).A+"",width:"303",height:"980"})}),"\n"]}),"\n",(0,a.jsxs)(t.li,{children:["\n",(0,a.jsx)(t.p,{children:"Now we need to attach the Service Bus we created as the output target, so under 'Job topology' click on 'Outputs'."}),"\n"]}),"\n",(0,a.jsxs)(t.li,{children:["\n",(0,a.jsx)(t.p,{children:"In the 'Outputs' window, click on 'Add output' and select 'Service Bus queue'"}),"\n",(0,a.jsx)(t.p,{children:(0,a.jsx)(t.img,{alt:"Add Output",src:n(3976).A+"",width:"597",height:"539"})}),"\n"]}),"\n",(0,a.jsxs)(t.li,{children:["\n",(0,a.jsx)(t.p,{children:"Again, it should bring up a window with the queue configuration details already pre-populated, but verify all the details and update as needed and then click 'Save'."}),"\n",(0,a.jsx)(t.p,{children:(0,a.jsx)(t.img,{alt:"Service Bus Config",src:n(581).A+"",width:"351",height:"1006"})}),"\n"]}),"\n",(0,a.jsxs)(t.li,{children:["\n",(0,a.jsx)(t.p,{children:"To process the records from AKS we'll need to parse some JSON, so we need to add a function to the Stream Analytics Job to parse JSON. Under 'Job topology' click on 'Functions'."}),"\n"]}),"\n",(0,a.jsxs)(t.li,{children:["\n",(0,a.jsx)(t.p,{children:"In the functions window, click on 'Add Function' and then select 'Javascript UDF' for Javascript User Defined Function"}),"\n",(0,a.jsx)(t.p,{children:(0,a.jsx)(t.img,{alt:"Create Function",src:n(7956).A+"",width:"616",height:"540"})}),"\n"]}),"\n",(0,a.jsxs)(t.li,{children:["\n",(0,a.jsx)(t.p,{children:"In the 'Function alias' name the function 'jsonparse' and in the editor window add the following:"}),"\n",(0,a.jsx)(t.pre,{children:(0,a.jsx)(t.code,{className:"language-javascript",children:"function main(x) {\nvar json = JSON.parse(x);  \nreturn json;\n}\n"})}),"\n",(0,a.jsx)(t.p,{children:(0,a.jsx)(t.img,{alt:"Function",src:n(3016).A+"",width:"832",height:"298"})}),"\n"]}),"\n",(0,a.jsxs)(t.li,{children:["\n",(0,a.jsx)(t.p,{children:"Click on 'Save' to save the function"}),"\n"]}),"\n",(0,a.jsxs)(t.li,{children:["\n",(0,a.jsx)(t.p,{children:"Now, under 'Job topology' in the stream analytics job, click on 'Query' to start adding a query. When loaded, the inputs, outputs and functions should pre-populate for you."}),"\n"]}),"\n",(0,a.jsxs)(t.li,{children:["\n",(0,a.jsx)(t.p,{children:"We'll first create a basic query to select all records and ship them to the output target. In the query window paste the following, updating the input and output values to match the names of your input and output. The function name should be the same unless you changed it."}),"\n",(0,a.jsx)(t.pre,{children:(0,a.jsx)(t.code,{className:"language-sql",children:"WITH DynamicCTE AS (\nSELECT UDF.jsonparse(individualRecords.ArrayValue.properties.log) AS log\nFROM [logfilterhub28026]\nCROSS APPLY GetArrayElements(records) AS individualRecords\n)\nSELECT *\nINTO [kubeauditlogs]\nFROM DynamicCTE\n"})}),"\n"]}),"\n",(0,a.jsxs)(t.li,{children:["\n",(0,a.jsx)(t.p,{children:"Click 'Save Query' at the top of the query window"}),"\n",(0,a.jsx)(t.p,{children:(0,a.jsx)(t.img,{alt:"Save Query",src:n(8009).A+"",width:"1249",height:"427"})}),"\n"]}),"\n",(0,a.jsxs)(t.li,{children:["\n",(0,a.jsx)(t.p,{children:"In the top left of the query window, click on 'Start Job' to kick off the stream analytics job."}),"\n"]}),"\n",(0,a.jsxs)(t.li,{children:["\n",(0,a.jsx)(t.p,{children:"In the 'Start job' window, leave the start time set to 'Now' and click 'Start'"}),"\n",(0,a.jsx)(t.p,{children:(0,a.jsx)(t.img,{alt:"Start Job",src:n(1811).A+"",width:"1752",height:"485"})}),"\n"]}),"\n",(0,a.jsxs)(t.li,{children:["\n",(0,a.jsx)(t.p,{children:"Click on the 'Overview' tab in the stream analytics job, and refresh every once in a while until the job 'Status' says 'Running'"}),"\n",(0,a.jsx)(t.p,{children:(0,a.jsx)(t.img,{alt:"Job Running",src:n(5395).A+"",width:"972",height:"320"})}),"\n"]}),"\n",(0,a.jsxs)(t.li,{children:["\n",(0,a.jsx)(t.p,{children:"Navigate back to your Resource Group and then click on your service bus namespace."}),"\n"]}),"\n",(0,a.jsxs)(t.li,{children:["\n",(0,a.jsx)(t.p,{children:"Assuming everything worked as expected you should now be seeing a lot of messages coming through the Service Bus Queue"}),"\n",(0,a.jsx)(t.p,{children:(0,a.jsx)(t.img,{alt:"Service Bus Namespace with Data",src:n(4168).A+"",width:"1580",height:"919"})}),"\n"]}),"\n",(0,a.jsxs)(t.li,{children:["\n",(0,a.jsx)(t.p,{children:"Click on the queue at the bottom of the screen to open the Queue level view"}),"\n"]}),"\n",(0,a.jsxs)(t.li,{children:["\n",(0,a.jsx)(t.p,{children:"At the queue level, click on 'Service Bus Explorer' to view the live records"}),"\n"]}),"\n",(0,a.jsxs)(t.li,{children:["\n",(0,a.jsx)(t.p,{children:"To view the records already created' click on 'Peek from start' and then choose a record to view"}),"\n",(0,a.jsx)(t.p,{children:(0,a.jsx)(t.img,{alt:"Live Audit Record",src:n(5521).A+"",width:"1569",height:"766"})}),"\n"]}),"\n",(0,a.jsxs)(t.li,{children:["\n",(0,a.jsx)(t.p,{children:"Navigate back to the stream analytics job and click on 'Stop job' to stop sending records through to the service bus."}),"\n"]}),"\n"]}),"\n",(0,a.jsx)(t.p,{children:"Great! You should now have a very basic stream analytics job that takes the control plane 'kube-audit' log from an AKS cluster through Event Hub, queries that data and then pushes it to a Service Bus Queue. While this is great, the goal is to filter out some records, so lets move on to that!"}),"\n",(0,a.jsx)(t.h2,{id:"setup-a-test-workload-to-trigger-audit-log-entries",children:"Setup a test workload to trigger audit log entries"}),"\n",(0,a.jsx)(t.p,{children:"To test out our stream analytics query, we need some test data we can filter on. Let's create some requests to the API server that will be denied. To do that we'll create a service account with no rights and then create a test pod using that service account. We'll then use the service account token to try to reach the Kubernetes API server."}),"\n",(0,a.jsx)(t.pre,{children:(0,a.jsx)(t.code,{className:"language-bash",children:'# Create a new namespace\nkubectl create ns demo-ns\n\n# Create a service account in the namespace\nkubectl create sa demo-user -n demo-ns\n\n# Create a test secret\nkubectl create secret generic demo-secret -n demo-ns --from-literal \'message=hey-there\'\n\n# Check that you can read the secret\nkubectl get secret demo-secret -n demo-ns -o jsonpath=\'{.data.message}\'|base64 --decode\n\n# Create a test pod to try to query the API server\nkubectl run curlpod --rm -it \\\n--image=curlimages/curl -n demo-ns \\\n--overrides=\'{ "spec": { "serviceAccount": "demo-user" }  }\' -- sh\n\n#############################################\n# From within the pod run the following\n#############################################\n# Point to the internal API server hostname\nexport APISERVER=https://kubernetes.default.svc\n\n# Path to ServiceAccount token\nexport SERVICEACCOUNT=/var/run/secrets/kubernetes.io/serviceaccount\n\n# Read this Pod\'s namespace\nexport NAMESPACE=$(cat ${SERVICEACCOUNT}/namespace)\n\n# Read the ServiceAccount bearer token\nexport TOKEN=$(cat ${SERVICEACCOUNT}/token)\n\n# Reference the internal certificate authority (CA)\nexport CACERT=${SERVICEACCOUNT}/ca.crt\n\n# Explore the API with TOKEN \n# This call will pass\ncurl --cacert ${CACERT} --header "Authorization: Bearer ${TOKEN}" -X GET ${APISERVER}/api\n\n# This call to get secrets will fail\ncurl --cacert ${CACERT} --header "Authorization: Bearer ${TOKEN}" -X GET ${APISERVER}/api/v1/namespaces/$NAMESPACE/secrets/\n\n# Now run it under a watch to trigger continuous deny errors\nwatch \'curl --cacert ${CACERT} --header "Authorization: Bearer ${TOKEN}" -X GET ${APISERVER}/api/v1/namespaces/$NAMESPACE/secrets/\'\n'})}),"\n",(0,a.jsx)(t.h2,{id:"update-stream-analytics-to-look-for-forbidden-requests",children:"Update Stream Analytics to Look for Forbidden Requests"}),"\n",(0,a.jsx)(t.p,{children:"So, we have a user trying to execute requests against our cluster for which they are not authorized. We can easily update our stream analytics query to filter out forbidden requests against our namespace."}),"\n",(0,a.jsxs)(t.ol,{children:["\n",(0,a.jsxs)(t.li,{children:["\n",(0,a.jsx)(t.p,{children:"Navigate back to your 'Stream Analytics' instances in the Azure Portal"}),"\n"]}),"\n",(0,a.jsxs)(t.li,{children:["\n",(0,a.jsx)(t.p,{children:"If the job is still running, make sure you click 'Stop job' as you cannot edit queries while the job is running"}),"\n"]}),"\n",(0,a.jsxs)(t.li,{children:["\n",(0,a.jsx)(t.p,{children:"Click on the 'Query' tab"}),"\n"]}),"\n",(0,a.jsxs)(t.li,{children:["\n",(0,a.jsx)(t.p,{children:"Update the query as follows, to filter out audit messages about our 'demo-ns' namespace that also have a status code of 403 (Forbidden)"}),"\n",(0,a.jsxs)(t.blockquote,{children:["\n",(0,a.jsxs)(t.p,{children:[(0,a.jsx)(t.strong,{children:"Note:"})," Be sure that your 'FROM' still points to your Event Hub input target and that your 'INTO' still points to your Service Bus output target."]}),"\n"]}),"\n",(0,a.jsx)(t.pre,{children:(0,a.jsx)(t.code,{className:"language-sql",children:" WITH DynamicCTE AS (\n SELECT UDF.jsonparse(individualRecords.ArrayValue.properties.log) AS log\n FROM [logfilterhub28026]\n CROSS APPLY GetArrayElements(records) AS individualRecords\n )\n SELECT *\n INTO [kubeaudit]\n FROM DynamicCTE\n WHERE log.objectRef.namespace = 'demo-ns'\n AND log.responseStatus.code = 403\n"})}),"\n",(0,a.jsx)(t.p,{children:(0,a.jsx)(t.img,{alt:"Updated Query Window",src:n(1449).A+"",width:"1298",height:"513"})}),"\n"]}),"\n",(0,a.jsxs)(t.li,{children:["\n",(0,a.jsx)(t.p,{children:"Click 'Save query'"}),"\n"]}),"\n",(0,a.jsxs)(t.li,{children:["\n",(0,a.jsx)(t.p,{children:"Once the save completes click 'Start Job'"}),"\n"]}),"\n"]}),"\n",(0,a.jsx)(t.p,{children:"Once your job is started, you should be able to navigate back to your Service Bus Queue and watch the messages flowing through."}),"\n",(0,a.jsx)(t.p,{children:(0,a.jsx)(t.img,{alt:"Filtered Messages",src:n(5524).A+"",width:"1773",height:"708"})}),"\n",(0,a.jsx)(t.h2,{id:"conclusion",children:"Conclusion"}),"\n",(0,a.jsx)(t.p,{children:"Congratulations! You now have an end-to-end fully working Stream Analytics instance that can filter AKS control plane logs to extract specific messages. You can manipulate the diagnostic settings to add additional logs to the input and modify the query to extract the exact messages critical to your cluster's health and security. This is an extremely versatile solution that is also capable of handling log records of multiple clusters across your enterprise."})]})}function u(e={}){const{wrapper:t}={...(0,r.R)(),...e.components};return t?(0,a.jsx)(t,{...e,children:(0,a.jsx)(d,{...e})}):d(e)}},581:(e,t,n)=>{n.d(t,{A:()=>s});const s=n.p+"assets/images/sa-servicebus-config-9182e36515ff344d683c7fc34846dcd1.jpg"},735:(e,t,n)=>{n.d(t,{A:()=>s});const s=n.p+"assets/images/sa-job-create-instance-63f770088d59ec19c065713eb792dc7a.jpg"},1449:(e,t,n)=>{n.d(t,{A:()=>s});const s=n.p+"assets/images/sa-403-query-7b6159d3e86712bd830c5eaa1fbbe6f4.jpg"},1811:(e,t,n)=>{n.d(t,{A:()=>s});const s=n.p+"assets/images/sa-start-job-f60feaff9f6ddb6263722ddaf7f2b97c.jpg"},2428:(e,t,n)=>{n.d(t,{A:()=>s});const s=n.p+"assets/images/sa-job-inputs-8cde4e621406ae680a459f2a8831687a.jpg"},3016:(e,t,n)=>{n.d(t,{A:()=>s});const s=n.p+"assets/images/sa-javascript-udf-928667029ff39c9443d25a1fea93076f.jpg"},3076:e=>{e.exports=JSON.parse('{"permalink":"/2024/08/15/aks-control-plane-log-filtering","editUrl":"https://github.com/appdevgbb/gbb-blog/tree/main/docusaurus/blog/2024-08-15/aks-control-plane-log-filtering/index.md","source":"@site/blog/2024-08-15/aks-control-plane-log-filtering/index.md","title":"Using Stream Analytics to Filter AKS Control Plane Logs","description":"Using Azure Stream Analytics to filter Kubernetes control plane log data from AKS diagnostics in order to isolate critical data and reduce log retention cost.","date":"2024-08-15T00:00:00.000Z","tags":[],"readingTime":10.14,"hasTruncateMarker":true,"authors":[{"name":"Steve Griffith","title":"Principal Cloud Architect, Azure Global Black Belt","url":"https://github.com/swgriffith","socials":{"x":"https://x.com/SteveGriffith","github":"https://github.com/swgriffith"},"imageURL":"https://github.com/swgriffith.png","key":"steve_griffith","page":null}],"frontMatter":{"authors":["steve_griffith"],"date":"2024-08-15","description":"Using Azure Stream Analytics to filter Kubernetes control plane log data from AKS diagnostics in order to isolate critical data and reduce log retention cost.","tags":[],"title":"Using Stream Analytics to Filter AKS Control Plane Logs"},"unlisted":false,"prevItem":{"title":"Multi-Cluster Layer 4 Load Balancing with Fleet Manager","permalink":"/2024/09/06/multi-cluster-layer-4-load-balancing-with-fleet-manager"},"nextItem":{"title":"Using Project KAITO in AKS","permalink":"/2024/04/16/aks-kaito"}}')},3178:(e,t,n)=>{n.d(t,{A:()=>s});const s=n.p+"assets/images/rg-create-99803d7b32b0e097c0deb252707b0205.jpg"},3908:(e,t,n)=>{n.d(t,{A:()=>s});const s=n.p+"assets/images/sa-event-hub-config-ebc016ee9a33439bfa889b1c55b13b51.jpg"},3976:(e,t,n)=>{n.d(t,{A:()=>s});const s=n.p+"assets/images/sa-add-output-2a60e9127196c7669392867820b9d34d.jpg"},4168:(e,t,n)=>{n.d(t,{A:()=>s});const s=n.p+"assets/images/sb-namespace-live-19fd1b1681abc1e02cbbb1543e021929.jpg"},5395:(e,t,n)=>{n.d(t,{A:()=>s});const s=n.p+"assets/images/sa-job-status-running-0b03c0ac435fed6ab0a0d05f1a1546a9.jpg"},5521:(e,t,n)=>{n.d(t,{A:()=>s});const s=n.p+"assets/images/sb-audit-record-d16aab23dd67edf6db6222284941d72d.jpg"},5524:(e,t,n)=>{n.d(t,{A:()=>s});const s=n.p+"assets/images/sb-filtered-messages-c6013da3b7b2ffb21ae0905c19b494df.jpg"},7816:(e,t,n)=>{n.d(t,{A:()=>s});const s=n.p+"assets/images/sa-job-create-input-f54413dfdecd3bf2e930bd55e5e521ad.jpg"},7883:(e,t,n)=>{n.d(t,{A:()=>s});const s=n.p+"assets/images/sa-job-search-0e9811af2fb29f0c191495a426ca018c.jpg"},7956:(e,t,n)=>{n.d(t,{A:()=>s});const s=n.p+"assets/images/sa-create-function-c327143655504ecfeb0cbf5fbf19be87.jpg"},8009:(e,t,n)=>{n.d(t,{A:()=>s});const s=n.p+"assets/images/sa-save-query-720e75066a0399cde63b0d3154192468.jpg"},8257:(e,t,n)=>{n.d(t,{A:()=>s});const s=n.p+"assets/images/sa-job-search-result-ae62aa50a6a18c5e7884f32d560498c2.jpg"},8453:(e,t,n)=>{n.d(t,{R:()=>i,x:()=>o});var s=n(6540);const a={},r=s.createContext(a);function i(e){const t=s.useContext(r);return s.useMemo(function(){return"function"==typeof e?e(t):{...t,...e}},[t,e])}function o(e){let t;return t=e.disableParentContext?"function"==typeof e.components?e.components(a):e.components||a:i(e.components),s.createElement(r.Provider,{value:t},e.children)}}}]);